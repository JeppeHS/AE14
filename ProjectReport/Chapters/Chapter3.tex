% Chapter 3

\chapter{Project 2b: Radix sort} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 3. \emph{Radix sort}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------


\section{Implementations}
This project describes experiments done with different sorting algorithms for sorting arrays of int keys. The implementations centers around radix sort, but we also perform experiment with QuickSort and CountingSort to have something to compare with.
All algorithms in this project is based on approaches in \citep{radixSort}.
They all use $O(n)$, where $n$ is size of the input array.
The implementations have two methods:
\begin{lstlisting}
  void setup(int arrSize);
  int* sort(int* array, int arrSize);
\end{lstlisting}
\verb!setup! is used to set up the algorithms and \verb!sort! sorts the array, which is the only one we measure in our experiments.

The algorithms that sort based on digits, all assume that a digit, D, is 8 bits and the size of an int, K, is 32 bits.
The goal of this project is to implement a Multi-core Radix Sort which uses both Most Significant Digit (MSD) - and Lowest Significant Digit (LSD) Radix Sort, and compare this implementation with other relevant sorting algorithms.


\subsection{Counting sort (CS)}
We start by finding the greatest value in the list gKey.
gKey = Max(Array)+1
We use gKey to create a new array C and for every entry in C we set the value to 0.
in line 4-5 we go through the input array and use the Histogram array to keep trak of how many of a specific element we have, so for all the elements in array we go to the equvalent index in Histogram and increase it by 1.
In line 6-7 we use the Histogram to calculate the starting index of each key in array.
In the last loop we go through the Histogram array and we iterate from the last index and down to the beginning of the array.
The index of Histogram[array[j]-1] is where the j'th element of array should be in the result array.
Then we count down the Histogram[array[j]] by 1.
This work for the case where we have multiple of the same key and in the case where we have only one of each key, because in line 11 we decrease the starting index by 1 after having placed one instance of the key, so the previous won't be overwritten.
\lstinputlisting[language=C++, firstline=32, lastline=46, numbers=left]{./Figures/Project2b/CountingSort.cpp}


\subsection{Quick sort (QS)}
We use a Quick Sort from a \verb!C++! library because we want to compare our other algorithms with one that has a running time of $ O(n\cdot \log n) $ which Quick Sort does.
We call the library function in line 1 which takes an array, the size of the array, the type of elements (int in our case) and a compare function.
\lstinputlisting[language=C++, firstline=20, lastline=21, numbers=left]{./Figures/Project2b/QuickSort.cpp}
The compare function states that the input should e sorted from the smallest key to the greatest.
\lstinputlisting[language=C++, firstline=13, lastline=16, numbers=left]{./Figures/Project2b/QuickSort.cpp}


\subsection{Least significant digit (LSD)}
To have something to compare the Multi-core Radix Sort to, we implemented, among others, Least Significant Digit (LSD) radix sort. 
The idea is to sort the input array of keys into buckets starting from the lowest significant digit. After each sorting into buckets for a digit an array sorted from the that digit is produced. 
This is done for each digit until the input array is fully sorted. 

The implemtation uses C++ \verb!std:queue! structure to simulate buckets. We assume that this data structure utilizes memory and computation quite effectively, and it seem logical to use this instead of creating our own bucket data structure.
In the method 'sort' the pgram sorts the array as mentioned before, by iterating over the digits starting from the lowest significant one. At each iteration sorting the keys into buckets and then creating a new array from these buckets.
\begin{lstlisting}[numbers=left]
...
for (int i = 0; i < N_PASSES; i++) {
  for (int j = 0; j < arrSize; j++) {
    // Add to bucket
    buckets[ (sortedArray[j] >> (K-i*D)) & MASK_D ].push(sortedArray[j]);
  }
  // Create sorted array from buckets
  int sortArrIdx = 0;
  for (int k = 0; k < N_BUCKETS; k++) {
    while(!buckets[k].empty()) {
      sortedArray[sortArrIdx] = buckets[k].front();
      buckets[k].pop();
      sortArrIdx++;
    }
  }
}
\end{lstlisting}
\verb!sortedArray[j] >> (K-i*D)) & MASK_D! gets the digit we want to look at by right shifting the value and anding it with a bit mask containing 0s except for the lowest D bits, which is 1s.

The algorithm was straight forward to implement an contains no complex computation. If one wanted to improve performance a differen datastructure for buckets could maybe be used.



\subsection{Most significant digit (MSD)}
MSD radix sort is very similar to LSD. However, we now sort the input by looking at the digits in descending order.
After distributing the elements in buckets according to the most significant, these buckets are then sorted recursively.

The MSD radix sort is implemented as follows:
\begin{lstlisting}[numbers=left]
  // Pass 0
  queue<int> buckets[N_BUCKETS];
  for (int i = 0; i < arrSize; i++) {
    // Add to bucket
    buckets[ sortedArray[i] >> (K-D) ].push(sortedArray[i]);
  }
  // Pass 1 (and the rest, recursively)
  for (int b = 0; b < N_BUCKETS; b++) {
    msdRecursive(buckets[b], 1);
  }
  return sortedArray;
\end{lstlisting}

It makes use of the following recursive method:
\begin{lstlisting}[numbers=left]
void msdRecursive(queue<int> bucket, int pass) {
  if (bucket.empty()) return;
  
  // Base case (this bucket is already fully sorted).
  if (pass == N_PASSES) {
    while(!bucket.empty()) {
      sortedArray[sortArrIdx] = bucket.front();
      bucket.pop();
      sortArrIdx++;
    }
    return;
  }
  // Sort this bucket into some new buckets.
  queue<int> buckets[N_BUCKETS];
  while(!bucket.empty()) {
    const int key = bucket.front();
    bucket.pop();
    // Add to bucket
    buckets[ (key >> (K - (pass+1)*D)) & MASK_D ].push(key);
  }
    // Example (K=8, D=2, pass=1, so we have already sorted by AB, and now we look at CD):
    // (ABCDEFGH >> (8 - (1+1)*2)) & 00000011
    // (ABCDEFGH >> 4) & 00000011
    //  0000ABCD & 00000011
    //  000000CD

  // Now, sort all buckets recursively.
  for (int b = 0; b < N_BUCKETS; b++) {
    msdRecursive(buckets[b], pass+1);
  }
}
\end{lstlisting}

\subsection{MSD - using arrays (MSD\_arr)}
This version of MSD radix sort makes use of one long array for each digit to by.
These arrays are then of length \verb!N_KEYS*N_BUCKETS!. When we choose the number of buckets to be $2^8=256$, this would conceivably use that much more memory.
However, when we only declare the arrays without initializing, the paged virtual memory can handle this kind of array by mapping the physical memory only when the pages are first accessed \citep{radixSort}.


\subsection{Multicore radix sort (MCR)}
The implementation of Multi-core Radix Sort (MCR) is based on the approach in \citep{radixSort}. The idea behind is to use the benefits of both MSD and LSD and making the algorithm parallel to decrease computation time. 
The algorithm first partitions the input array into buckets with based on MSD and then sort each of theses buckets locally with using LSD.  
MSD has the disavangtage of not being very effective on arrays of small size or values is close to each other, because it can results of a lot of empty buckets. 
But has the advantage that when values have the same digit these doesn't have to be moved around. LSD on the other hand will have to move values that share prefix around again and again.
LSD has the advantage of handling non-uniform distribution of values better than MSD, but has the tradeoff of copying data around.  

The implementation is based on the pseudocode from the forementioned article:
\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{./Figures/Project2b/MultiCoreRadix_Pseudo.jpg}
		\rule{35em}{0.5pt}
	\caption[Multicore radix pseudocode]{
	Pseudocode for Multi-core Radix Sort
	}
	\label{fig:Branch_misses}
\end{figure}
As in the pseudocode the program starts out by sorting the array based on the most significant digit in parallel, then serial compute output indicies (PrefixSum in the pseudocode) and finally parallel sort each bucket based on LSD.  
The parallel parts is implemented using POSIX threads (\verb!<pthread.h>!), which by default utilizes multicore CPUs by starting each thread on a new CPU.

The program has two 2D arrays which respectively holds buckets and bucket histograms for each thread. These are called threadBucketArrays and threadNextArrays.
Each of the bucket arrays in threadBucketArrays inititally took up N x M space, where N is elements in the input array and M is number of buckets.
This means a lot of space had to be reserved by the program. To minimize this space usage, N is bound by the number of elements assigned to the current thread.
This yields that each bucket array takes up (N / P) x M, where P is the number of threads. 

The parallel MSD part (first part) assigns part of the input array to each thread, which then sort the elements int buckets based on the most significant digit.
The sorting is saved in the formentioned shared threadBucketArrays using threadNextArrays to index these bucket arrays:
\begin{lstlisting}
...
bucketArray[ putInBucket*nElemsAssigned[tInfo->threadNum] + nextArray[putInBucket] ] = inputArray[i];
nextArray[putInBucket]++; 
... 
\end{lstlisting}
bucketArray and nextArray coresponds to the threads arrays in threadBucketArrays and threadNextArrays.

The next part consist of the program computing (serial) output indices used to index the output array by traversing over the all the threads nextArrays.   
The array computed from this, ouputMSDStartIndices, is a kind of prefix sum over sizes of the MSD-bucket, but where the values are shifted on to the right in the array (i.e. the first element is 0).

In the last part, the MSD buckets is divided among the threads, which sort the assigned buckets locally based on LSD and then write sorted values to the output array.
For each MSD bucket assigned to a thread, it first sort the values in the bucket into new buckets (locally) based on the lowest significant digit. This is straight forward.
Then traversing through the bucket sorted by lowest significant digit, the values are divided into buckets depending on the second lowest significant digit.
And in same traversal a histogram for the third lowest significant digit is produces.
\begin{lstlisting}
...
  for (int bucket = 0; bucket < nBuckets; bucket++) {
    for (int i = 0; i < nexts0[bucket]; i++) {
      elem = buckets0[bucket*arraySize + i];

      // Put in bucket
      putInBucket = (elem >> shiftRight2nLast) & lsdBitMask;
      buckets1[putInBucket*arraySize + nexts1[putInBucket]] = elem;
      nexts1[putInBucket]++;

      // Histogram
      histIdx = (elem >> shiftRightLast) & lsdBitMask;
      histogram2[histIdx]++;
    }
  }
...
\end{lstlisting}
This histogram is then used to produce a prefix sum following same procedure as for the output indices.
\begin{lstlisting}
... 
  prefixSum2[0] = 0;
    for (int i = 0; i < nBuckets; i++) {
      // Prefix sum
      if (i != nBuckets -1) {
	prefixSum2[i+1] = prefixSum2[i] + histogram2[i];
      } 
  }
...
\end{lstlisting}

This prefix sum is used together with the calculated output indices (\verb!ouputMSDStartIndices!) to index the sorted values to the correct positions int the output array.
\begin{lstlisting}
...
  // Last pass: write to output array
  for (int bucket = 0; bucket < nBuckets; bucket++) {
    for (int i = 0; i < nexts1[bucket]; i++) {
      elem = buckets1[bucket*arraySize + i];

      putInBucket = (elem >> shiftRightLast) & lsdBitMask;

      outputIdx = startIdxForMSDBucket + prefixSum2[putInBucket];

      prefixSum2[putInBucket]++;
      sortedArray[outputIdx] = elem;
    }
  }
... 
\end{lstlisting}
Where \verb!startIdxForMSDBucket = ouputMSDStartIndices[msdBucket]!.
This trick by using the computed prefix sum for the third lowest significant digit, saves a traversal of the buckets and makes the algorithm a bit faster.

The program uses hardcoded D and K, where D is number of bits per digit and K is number of bits per integer. Our implementation assumes that these values always is K = 32 and D = 8.
The implementation could be made generic, taking an abitrary K and D, but we didn't have the time and the algorithm in the article is depends on these values of D and K.
A generic solution could be achieved simply by adding LSD sorting in between the first LSD sorting and the second to last LSD sorting.

It turns out that the parallel parts of this implementation in fact doesn't run in parallel. This is with high probability because some methods locks the program to make serial computation.
We now for a fact that the \verb!srand! methods does this, but what other functionality in the implementation has this effect, we don't know.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{./Figures/Project2b/multicore_cpu_usage.png}
		\rule{35em}{0.5pt}
	\caption[Multicore CPU usage]{
	MCR threads running in serial.
	}
	\label{fig:multicore_cpu_usage}
\end{figure}

As seen in figure \ref{fig:multicore_cpu_usage}, different threads on different CPUs is started, but these doesn't run in parallel.

\section{Results and discussion}

As seen in figure \ref{fig:Branch_misses_p2b}, CS has the fewest branch misses, which at the same time is approximately constant. This is because of the predictive behavior of CS i.e. it has no conditionals.
Both MCR and MSD\_arr follows the same overall course. The reason for this is that they both use the same data structure for storing their buckets which is one long array handled by paged virtual memory.
On the other hand, MSD and LSD uses queues for buckets, which is handled in a different way.
We have no control over the implementation of QS, so we cannot explain its behavior.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{./Figures/Project2b/Branch_misses.pdf}
		\rule{35em}{0.5pt}
	\caption[Branch misses]{
	Branch misses for sorting algorithms based on array size.
	}
	\label{fig:Branch_misses_p2b}
\end{figure}


In figure \ref{fig:Cache_misses_p2b} and \ref{fig:Cache_refs_p2b}, the MSDs are highest because they constantly access different buckets, which then have to be loaded into cache.
Disregarding QS, MCR has the fewest cache refs and misses. Even though MCR is prevented from utilizing multiple CPUs in a parallel manner, each thread has its own L1 and L2 cache and they only need to consider a fraction of the input array.
This utilizes the cache more efficiently.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{./Figures/Project2b/Cache_misses.pdf}
		\rule{35em}{0.5pt}
	\caption[Cache misses]{
	Cache misses for sorting algorithms based on array size.
	}
	\label{fig:Cache_misses_p2b}
\end{figure}

\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{./Figures/Project2b/Cache_refs.pdf}
		\rule{35em}{0.5pt}
	\caption[Cache refs]{
	Number of cache references for sorting algorithms based on array size.
	}
	\label{fig:Cache_refs_p2b}
\end{figure}




The figures \ref{fig:Cpu_cycles_p2b} and \ref{fig:Instructions_p2b} looks similar.
The algorithm that using fewest instructions/cycles is MCR, which at first glance seems surprising for such a complex algorithm. However, if we consider the trick that avoids one of the four passes, this should give speedup factor of about $2^D$.
The algorithm with the highest number of base instructions is MSD, which can be explained by the number of queues created in the recursive structure, which all need to be maintained. 


\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{./Figures/Project2b/Cpu_cycles.pdf}
		\rule{35em}{0.5pt}
	\caption[CPU cycles]{
	Measure CPU cycles for sorting algorithms based on array size.
	}
	\label{fig:Cpu_cycles_p2b}
\end{figure}

\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{./Figures/Project2b/Instructions.pdf}
		\rule{35em}{0.5pt}
	\caption[Instructions]{
	Hardware instructions for sorting algorithms based on array size.
	}
	\label{fig:Instructions_p2b}
\end{figure}



\section{Conclusion}
During the projects we have learned the significance of different cache usage techniques.
In project one, the most surprising result is that vEB is competing with the other implementations on the execution time even though vEB uses far more instructions.

In project three, MCR turned out to dominate the others, even though it didn't run in a parallel manner. 
Another thing we didn't expect, was the advantage of using (uninitialized) arrays over queues as buckets.

